{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "import numpy as np\n",
    "\n",
    "path='../sherlock_holmes_all.txt'\n",
    "file=open(path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "text=file.read().lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' to sherlock holmes she is always the woman. i have seldom heard him\\n mention her under any other name. in his eyes she eclipses and\\n predominates the whole of her sex. it was not that he felt any\\n em'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text[0:200]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_len=60   #number of characters\n",
    "step=3 #  skip over characteres\n",
    "\n",
    "sentences=[]\n",
    "next_chars=[]\n",
    "\n",
    "for i in range(0,len(text)-max_len,step):\n",
    "    \n",
    "    sentences.append(text[i:i+max_len])\n",
    "    next_chars.append(text[i+max_len])  #next character after i:i+maxlen (i+maxlen exclude), -> goes for i+maxlen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' to sherlock holmes she is always the woman. i have seldom h'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "681782"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "60"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(sentences[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['\\t', '\\n', ' ', '!', '\"', '&', \"'\", '(', ')', ',', '-', '.', '0', '1', '2', '3', '4', '5', '6', '7', '8', '9', ':', ';', '?', '[', ']', '`', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z', '¢', '£', '¨', '©', 'ª', '®', '°', '´', '½', 'â', 'ã', '€', '™']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "67"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "char_list=sorted(list(set(text)))  #list unique, sorted\n",
    "print(char_list)\n",
    "len(char_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#char_dict_index={}\n",
    "char_dict_index=dict((char_,i) for i,char_ in enumerate(char_list))\n",
    "index_dict_char=dict((i,char_) for i,char_ in enumerate(char_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'\\t': 0, '\\n': 1, ' ': 2, '!': 3, '\"': 4, '&': 5, \"'\": 6, '(': 7, ')': 8, ',': 9, '-': 10, '.': 11, '0': 12, '1': 13, '2': 14, '3': 15, '4': 16, '5': 17, '6': 18, '7': 19, '8': 20, '9': 21, ':': 22, ';': 23, '?': 24, '[': 25, ']': 26, '`': 27, 'a': 28, 'b': 29, 'c': 30, 'd': 31, 'e': 32, 'f': 33, 'g': 34, 'h': 35, 'i': 36, 'j': 37, 'k': 38, 'l': 39, 'm': 40, 'n': 41, 'o': 42, 'p': 43, 'q': 44, 'r': 45, 's': 46, 't': 47, 'u': 48, 'v': 49, 'w': 50, 'x': 51, 'y': 52, 'z': 53, '¢': 54, '£': 55, '¨': 56, '©': 57, 'ª': 58, '®': 59, '°': 60, '´': 61, '½': 62, 'â': 63, 'ã': 64, '€': 65, '™': 66}\n"
     ]
    }
   ],
   "source": [
    "print(char_dict_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: '\\t', 1: '\\n', 2: ' ', 3: '!', 4: '\"', 5: '&', 6: \"'\", 7: '(', 8: ')', 9: ',', 10: '-', 11: '.', 12: '0', 13: '1', 14: '2', 15: '3', 16: '4', 17: '5', 18: '6', 19: '7', 20: '8', 21: '9', 22: ':', 23: ';', 24: '?', 25: '[', 26: ']', 27: '`', 28: 'a', 29: 'b', 30: 'c', 31: 'd', 32: 'e', 33: 'f', 34: 'g', 35: 'h', 36: 'i', 37: 'j', 38: 'k', 39: 'l', 40: 'm', 41: 'n', 42: 'o', 43: 'p', 44: 'q', 45: 'r', 46: 's', 47: 't', 48: 'u', 49: 'v', 50: 'w', 51: 'x', 52: 'y', 53: 'z', 54: '¢', 55: '£', 56: '¨', 57: '©', 58: 'ª', 59: '®', 60: '°', 61: '´', 62: '½', 63: 'â', 64: 'ã', 65: '€', 66: '™'}\n"
     ]
    }
   ],
   "source": [
    "print(index_dict_char)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['\\t', '\\n', ' ', '!', '\"', '&', \"'\", '(', ')', ',', '-', '.', '0', '1', '2', '3', '4', '5', '6', '7', '8', '9', ':', ';', '?', '[', ']', '`', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z', '¢', '£', '¨', '©', 'ª', '®', '°', '´', '½', 'â', 'ã', '€', '™']\n"
     ]
    }
   ],
   "source": [
    "print(char_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "67"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(char_dict_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#vectorization   len(sentences) * len(max_len) -> len(sentences) * len(max_len) * len(char_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=np.zeros((len(sentences),max_len,len(char_dict_index)),dtype=np.bool)\n",
    "y=np.zeros((len(next_chars),len(char_dict_index)),dtype=np.bool)\n",
    "\n",
    "for i,sentence in enumerate(sentences):\n",
    "    for j,char in enumerate(sentence):\n",
    "        \n",
    "        x[i,j,char_dict_index[char]]=1\n",
    "     \n",
    "    y[i,char_dict_index[next_chars[i]]]=1  #for i sequence (sentence) has a last letter\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(681782, 60, 67)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(681782, 67)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import LSTM,Dense\n",
    "from keras.models import Sequential\n",
    "\n",
    "model=Sequential()\n",
    "model.add(LSTM(128,input_shape=(max_len,len(char_dict_index))))\n",
    "model.add(Dense(len(char_dict_index), activation='softmax'))  #get the list of index, highest probability will be the index of next char as trained\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer=keras.optimizers.RMSprop(lr=0.01)\n",
    "model.compile(loss='categorical_crossentropy',optimizer=optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample(preds,temperature=1.0):\n",
    "    preds=np.asarray(preds).astype('float64')\n",
    "    preds=np.log(preds)/temperature\n",
    "    exp_preds=np.exp(preds)\n",
    "    preds=exp_preds/np.sum(exp_preds)\n",
    "    probas=np.random.multinomial(1,preds,1)\n",
    "    return np.argmax(probas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1\n",
      "Epoch 1/1\n",
      "681782/681782 [==============================] - 1546s 2ms/step - loss: 1.7359\n",
      "--- generating with seed: \", of course, claim the protection of the embassy for\n",
      " the ot\"\n",
      "--- temperature: 0.2\n",
      ", of course, claim the protection of the embassy for\n",
      " the ot--- temperature: 0.5\n",
      "the stately to the station to the stately of the strange the--- temperature: 1.2\n",
      "the book to the bare of\n",
      " the has until he\n",
      " have a street? \"b--- temperature: 1.5\n",
      "\n",
      " \"the dainly somethercy next questinand question to teledly"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import sys\n",
    "\n",
    "for epoch in range(1,2):\n",
    "    \n",
    "    print('epoch',epoch)\n",
    "    model.fit(x,y,batch_size=128,epochs=1)\n",
    "    start_index=random.randint(0,len(text)-max_len-1)\n",
    "    generated_text_=text[start_index:start_index+max_len]\n",
    "    print('--- generating with seed: \"'+generated_text_+'\"')\n",
    "    \n",
    "    for temperature in [0.2,0.5,1.2,1.5]:\n",
    "        print('--- temperature:', temperature)\n",
    "        sys.stdout.write(generated_text_)\n",
    "        generated_text=generated_text_\n",
    "        for i in range(400): #create a text of 400 character\n",
    "            \n",
    "            sampled=np.zeros((1,max_len,len(char_dict_index)))  #only one batch, one sentence, max len char,68 one hot\n",
    "            \n",
    "            for j, char in enumerate(generated_text): #generated text len 60 (max_len)\n",
    "                \n",
    "                sampled[0,j,char_dict_index[char]]=1.\n",
    "                \n",
    "            preds=model.predict(sampled,verbose=0)[0]    \n",
    "            pred_temp_argmax=sample(preds,temperature=temperature)\n",
    "            new_char=index_dict_char[pred_temp_argmax]\n",
    "            \n",
    "            generated_text +=new_char  #add the new guessed character\n",
    "            \n",
    "            generated_text=generated_text[1:]  #removed first char from beginning of the list\n",
    "            \n",
    "            sys.stdout.write(generated_text)\n",
    "            \n",
    "            sys.stdout.flush()\n",
    "            \n",
    "        print()\n",
    "            \n",
    "            \n",
    "            \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
