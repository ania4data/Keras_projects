{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "import numpy as np\n",
    "\n",
    "path='sherlock_holmes_all.txt'\n",
    "file=open(path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "text=file.read().lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' to sherlock holmes she is always the woman. i have seldom heard him\\n mention her under any other name. in his eyes she eclipses and\\n predominates the whole of her sex. it was not that he felt any\\n em'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text[0:200]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_len=60   #number of characters\n",
    "step=3 #  skip over characteres\n",
    "\n",
    "sentences=[]\n",
    "next_chars=[]\n",
    "\n",
    "for i in range(0,len(text)//3-max_len,step):\n",
    "    \n",
    "    sentences.append(text[i:i+max_len])\n",
    "    next_chars.append(text[i+max_len])  #next character after i:i+maxlen (i+maxlen exclude), -> goes for i+maxlen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' to sherlock holmes she is always the woman. i have seldom h'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "227248"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "60"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(sentences[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['\\t', '\\n', ' ', '!', '\"', '&', \"'\", '(', ')', ',', '-', '.', '0', '1', '2', '3', '4', '5', '6', '7', '8', '9', ':', ';', '?', '[', ']', '`', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z', '¢', '£', '¨', '©', 'ª', '®', '°', '´', '½', 'â', 'ã', '€', '™']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "67"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "char_list=sorted(list(set(text)))  #list unique, sorted\n",
    "print(char_list)\n",
    "len(char_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#char_dict_index={}\n",
    "char_dict_index=dict((char_,i) for i,char_ in enumerate(char_list))\n",
    "index_dict_char=dict((i,char_) for i,char_ in enumerate(char_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'\\t': 0, '\\n': 1, ' ': 2, '!': 3, '\"': 4, '&': 5, \"'\": 6, '(': 7, ')': 8, ',': 9, '-': 10, '.': 11, '0': 12, '1': 13, '2': 14, '3': 15, '4': 16, '5': 17, '6': 18, '7': 19, '8': 20, '9': 21, ':': 22, ';': 23, '?': 24, '[': 25, ']': 26, '`': 27, 'a': 28, 'b': 29, 'c': 30, 'd': 31, 'e': 32, 'f': 33, 'g': 34, 'h': 35, 'i': 36, 'j': 37, 'k': 38, 'l': 39, 'm': 40, 'n': 41, 'o': 42, 'p': 43, 'q': 44, 'r': 45, 's': 46, 't': 47, 'u': 48, 'v': 49, 'w': 50, 'x': 51, 'y': 52, 'z': 53, '¢': 54, '£': 55, '¨': 56, '©': 57, 'ª': 58, '®': 59, '°': 60, '´': 61, '½': 62, 'â': 63, 'ã': 64, '€': 65, '™': 66}\n"
     ]
    }
   ],
   "source": [
    "print(char_dict_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: '\\t', 1: '\\n', 2: ' ', 3: '!', 4: '\"', 5: '&', 6: \"'\", 7: '(', 8: ')', 9: ',', 10: '-', 11: '.', 12: '0', 13: '1', 14: '2', 15: '3', 16: '4', 17: '5', 18: '6', 19: '7', 20: '8', 21: '9', 22: ':', 23: ';', 24: '?', 25: '[', 26: ']', 27: '`', 28: 'a', 29: 'b', 30: 'c', 31: 'd', 32: 'e', 33: 'f', 34: 'g', 35: 'h', 36: 'i', 37: 'j', 38: 'k', 39: 'l', 40: 'm', 41: 'n', 42: 'o', 43: 'p', 44: 'q', 45: 'r', 46: 's', 47: 't', 48: 'u', 49: 'v', 50: 'w', 51: 'x', 52: 'y', 53: 'z', 54: '¢', 55: '£', 56: '¨', 57: '©', 58: 'ª', 59: '®', 60: '°', 61: '´', 62: '½', 63: 'â', 64: 'ã', 65: '€', 66: '™'}\n"
     ]
    }
   ],
   "source": [
    "print(index_dict_char)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['\\t', '\\n', ' ', '!', '\"', '&', \"'\", '(', ')', ',', '-', '.', '0', '1', '2', '3', '4', '5', '6', '7', '8', '9', ':', ';', '?', '[', ']', '`', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z', '¢', '£', '¨', '©', 'ª', '®', '°', '´', '½', 'â', 'ã', '€', '™']\n"
     ]
    }
   ],
   "source": [
    "print(char_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "67"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(char_dict_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#vectorization   len(sentences) * len(max_len) -> len(sentences) * len(max_len) * len(char_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=np.zeros((len(sentences),max_len,len(char_dict_index)),dtype=np.bool)\n",
    "y=np.zeros((len(next_chars),len(char_dict_index)),dtype=np.bool)\n",
    "\n",
    "for i,sentence in enumerate(sentences):\n",
    "    for j,char in enumerate(sentence):\n",
    "        \n",
    "        x[i,j,char_dict_index[char]]=1\n",
    "     \n",
    "    y[i,char_dict_index[next_chars[i]]]=1  #for i sequence (sentence) has a last letter\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(227248, 60, 67)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(227248, 67)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import LSTM,Dense\n",
    "from keras.models import Sequential\n",
    "\n",
    "model=Sequential()\n",
    "model.add(LSTM(128,input_shape=(max_len,len(char_dict_index))))\n",
    "model.add(Dense(len(char_dict_index), activation='softmax'))  #get the list of index, highest probability will be the index of next char as trained\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer=keras.optimizers.RMSprop(lr=0.01)\n",
    "model.compile(loss='categorical_crossentropy',optimizer=optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample(preds,temperature=1.0):\n",
    "    preds=np.asarray(preds).astype('float64')\n",
    "    preds=np.log(preds)/temperature\n",
    "    exp_preds=np.exp(preds)\n",
    "    preds=exp_preds/np.sum(exp_preds)\n",
    "    probas=np.random.multinomial(1,preds,1)\n",
    "    return np.argmax(probas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1\n",
      "Epoch 1/1\n",
      "227248/227248 [==============================] - 171s 751us/step - loss: 1.8886\n",
      "--- generating with seed: \"n eye-glass. the latter was colonel ross, the\n",
      " well-known sp\"\n",
      "--- temperature: 0.5\n",
      "n eye-glass. the latter was colonel ross, the\n",
      " well-known spock that where i sust opper had encapted those close think this for my the done would have a very such a part upon the was the are the with a lock the dress and i lond which this was a man to have a consince and ready that it is a before and a waid in the was a fanter a concenting the tridencl. he looked\n",
      " to the may of the passers and the done to such a little to a poncont have an a gettle this a \n",
      "epoch 2\n",
      "Epoch 1/1\n",
      "227248/227248 [==============================] - 166s 729us/step - loss: 1.5784\n",
      "--- generating with seed: \"\n",
      "\n",
      " \"one moment,\" said holmes, \"are you sure about this whist\"\n",
      "--- temperature: 0.5\n",
      "\n",
      "\n",
      " \"one moment,\" said holmes, \"are you sure about this whistle think to his han and all his compressives and seven a beliave and in his hands in the provers which we have a stain that i have the rest and persible that i should can geve and that i think that we have the daped that you will not to the mann of start to the man of the light started to me to be a man of little started that i have think that i may give my companion in could that the churge and a\n",
      "epoch 3\n",
      "Epoch 1/1\n",
      "227248/227248 [==============================] - 165s 728us/step - loss: 1.4965\n",
      "--- generating with seed: \"e in the meantime, and he used\n",
      " to write every day. i took t\"\n",
      "--- temperature: 0.5\n",
      "e in the meantime, and he used\n",
      " to write every day. i took the away to be a breakson. the had no was save a sister of the read and with something in she with your catrairs and disaquent, and so expreminary so married to in the in the same in his order that i had been and could have have been we know in the books. strang of the hustors. it was no with a proy of his interest. \"i should have her thank and had sull as a wife and and and had and paper in the of\n",
      "epoch 4\n",
      "Epoch 1/1\n",
      "227248/227248 [==============================] - 166s 732us/step - loss: 1.4572\n",
      "--- generating with seed: \" you please!\"\n",
      "\n",
      " the keen interest had passed out of holmes's\"\n",
      "--- temperature: 0.5\n",
      " you please!\"\n",
      "\n",
      " the keen interest had passed out of holmes's matter face of the little toot which was a secret in the man in the all that there was the man would what the manger and the table of the place, then, as i was do the were not be the certain\n",
      " of the the will be man. at the back to a finess at the word with the hard at me, the corner we do you to have been \"i to case to have the weel that i have the morning in the case. the was for the signely of \n",
      "epoch 5\n",
      "Epoch 1/1\n",
      "227248/227248 [==============================] - 166s 728us/step - loss: 1.4293\n",
      "--- generating with seed: \"ts name to\n",
      " the place.\n",
      "\n",
      " \"i was driven over by my employer, \"\n",
      "--- temperature: 0.5\n",
      "ts name to\n",
      " the place.\n",
      "\n",
      " \"i was driven over by my employer, with he sidequessed the lost passing which came the hars and them some the\n",
      " story of the stations a simple, and i was an excellent the papers of shoulder and come geft enough\n",
      " from the served. \"i should the look of no doubt when it was an encommonest to me and the supper the costable. the new streng to see the house contonsing of the street.\n",
      "\n",
      " \"'the ready remarked. \"i could see the same of let to \n",
      "epoch 6\n",
      "Epoch 1/1\n",
      "227248/227248 [==============================] - 167s 736us/step - loss: 1.4121\n",
      "--- generating with seed: \"the theatre with the young lady he\n",
      " suddenly, in the fog, ca\"\n",
      "--- temperature: 0.5\n",
      "the theatre with the young lady he\n",
      " suddenly, in the fog, can said that it's not the man and such a brideward of the stable of his will started upon the man as it is a companion, and what i was he is a sulpleful by the pace.\n",
      " it is the close in his with a should simple, and some off a missie of a came the child, and as the case, and i have dreadful by a down the cluster, and i have been a small street started with a man to be lick to the place, he was it w\n",
      "epoch 7\n",
      "Epoch 1/1\n",
      "227248/227248 [==============================] - 166s 730us/step - loss: 1.3994\n",
      "--- generating with seed: \"port. it was\n",
      " the rock of gibraltar, their largest and best \"\n",
      "--- temperature: 0.5\n",
      "port. it was\n",
      " the rock of gibraltar, their largest and best the case of morth is a case and remarked his hand and the practice of the were a very settle of the light and the lad to the league, sherlock holmes with a woman all watson,\" said holmes, and the door and read the court's to out all we and whither i cane that i have a signiff-carried arrest his came to done in the promottor, which was a singul the poftor of the papers. there is so the hand in the \n",
      "epoch 8\n",
      "Epoch 1/1\n",
      "227248/227248 [==============================] - 167s 733us/step - loss: 1.3866\n",
      "--- generating with seed: \"ngthy proceeding\n",
      " than holmes had imagined, for he did not r\"\n",
      "--- temperature: 0.5\n",
      "ngthy proceeding\n",
      " than holmes had imagined, for he did not recover of the man of his face that i have been the pronise and bething\n",
      " his subion person of the confed st. come to the table all took out to observe, the stable. i should not be some than can monther that the conturbly and his signiply that you see that i did, \"and he was my tried. the cheed of the kealon that i shall some very parand at the para time to him and face to sas in the best any more c\n",
      "epoch 9\n",
      "Epoch 1/1\n",
      "227248/227248 [==============================] - 167s 733us/step - loss: 1.4046\n",
      "--- generating with seed: \"s dark to me also, but i have hold of one idea which may\n",
      " le\"\n",
      "--- temperature: 0.5\n",
      "s dark to me also, but i have hold of one idea which may\n",
      " less oned to the side of my ment still with the single little little and day in th('s pit"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/paperspace/anaconda3/envs/fastai/lib/python3.6/site-packages/ipykernel_launcher.py:3: RuntimeWarning: divide by zero encountered in log\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ing who had stated that he had a scorts which has been seen at a bach them on the pressure that there was no under you that the presswants which was a ration. and he was a frightences of the business which could have been the for me as the man 4quart that he is the true. i felt that i had say that i have a wife \n",
      "epoch 10\n",
      "Epoch 1/1\n",
      "227248/227248 [==============================] - 168s 738us/step - loss: 1.3889\n",
      "--- generating with seed: \"ecially appealed to him, and the efforts of\n",
      " the police woul\"\n",
      "--- temperature: 0.5\n",
      "ecially appealed to him, and the efforts of\n",
      " the police would say some main\n",
      " in corning that you will press that he bride that i cannot be what on the camps when the later was as he say and\n",
      " completely as he could not have den. we may see that i was a private at the read a well, and so that i can see the curious ready to say that i have been carried the matter with the stranger bear the words in the crain who closed what is the chair and the wingly the tra\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import sys\n",
    "\n",
    "for epoch in range(1,11):\n",
    "    \n",
    "    print('epoch',epoch)\n",
    "    model.fit(x,y,batch_size=128,epochs=1)\n",
    "    start_index=random.randint(0,len(text)-max_len-1)\n",
    "    generated_text_=text[start_index:start_index+max_len]\n",
    "    print('--- generating with seed: \"'+generated_text_+'\"')\n",
    "    \n",
    "    for temperature in [0.5]: #[0.2,0.5,1.2,1.5]:\n",
    "        print('--- temperature:', temperature)\n",
    "        sys.stdout.write(generated_text_)\n",
    "        generated_text=generated_text_\n",
    "        \n",
    "        for i in range(400): #create a text of 400 character\n",
    "            \n",
    "            sampled=np.zeros((1,max_len,len(char_dict_index)))  #only one batch, one sentence, max len char,68 one hot\n",
    "            \n",
    "            for j, char in enumerate(generated_text): #generated text len 60 (max_len)\n",
    "                \n",
    "                sampled[0,j,char_dict_index[char]]=1.\n",
    "                \n",
    "            preds=model.predict(sampled,verbose=0)[0]    \n",
    "            pred_temp_argmax=sample(preds,temperature=temperature)\n",
    "            new_char=index_dict_char[pred_temp_argmax]\n",
    "            \n",
    "            generated_text +=new_char  #add the new guessed character\n",
    "            \n",
    "            generated_text=generated_text[1:]  #removed first char from beginning of the list\n",
    "            \n",
    "            sys.stdout.write(new_char)\n",
    "            \n",
    "            sys.stdout.flush()\n",
    "            \n",
    "        print()            \n",
    " \n",
    "\n",
    "\n",
    "# Epoch 1/1\n",
    "# 227248/227248 [==============================] - 178s 784us/step - loss: 1.6386\n",
    "# --- generating with seed: \"e permissible.\n",
    "#  was there any other spirit but rum in the ro\"\n",
    "# --- temperature: 0.2\n",
    "# e permissible.\n",
    "#  was there any other spirit but rum in the room and the chinness and the stange of the one of the companion of the stanged that i have a strange of the station of the stand and the cortainly that i have been and that i have a come that the containt of the stone of the stantly of the chind and the stand of the come that we have a strange of the stand of the possible and the strange of the containt. the entaid he was a stant of the stant and t\n",
    "# --- temperature: 0.5\n",
    "# e permissible.\n",
    "#  was there any other spirit but rum in the room, and the all a which was not one one of the pression of sto appear, and i have in in the dew dunce all in the certainly of the window, and the stall a de and shown he was the poor bearly, and and i shotle more chang of his one chain which was all and winding the late hear in the poor and i har the stone\n",
    "#  and and i was come black as the pass who was the might of a perve that he has been the pair\n",
    "# --- temperature: 1.2\n",
    "# e permissible.\n",
    "#  was there any other spirit but rum in the roghar, as me\n",
    "#  it was most hoasthered chill. \"my hope, and\n",
    "#  you gemve the elusuable was one oldmonemed\n",
    "#  stor an'k off muct\n",
    "#  lowty callo buf that bote blanlr mindied oblest  und. we am am now a compara holmeannsed morown of sep as i lise and befodd all , mr. how on able seal stooded well.\"\n",
    "\n",
    "#  \"pen the s, he went ard slelt\n",
    "#  pice are garce, some insnoped off\n",
    "#  de fornes. give little of i have a so it. fi\n",
    "# --- temperature: 1.5\n",
    "# e permissible.\n",
    "#  was there any other spirit but rum in the roose. \"theck e will, aftectin strace, as ne afty on. evententy-to on micemati arrsw thint.\n",
    "#  jy, gnnebhess?\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
